{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Moving to Neighborhood Sampler"
      ],
      "metadata": {
        "id": "8N9UxJ1AiM30"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install faiss-gpu\n",
        "!pip install torch\n",
        "!pip install torch_geometric\n",
        "!pip install faiss-cpu\n",
        "!pip install tqdm\n",
        "!pip install scapy\n",
        "!pip install geoopt\n",
        "\n",
        "# Install torch-scatter and torch-sparse compatible with your PyTorch version\n",
        "import torch\n",
        "torch_version = torch.__version__.split('+')[0]\n",
        "cuda_version = torch.version.cuda.replace('.', '')\n",
        "!pip install torch-scatter -f https://data.pyg.org/whl/torch-{torch_version}+cu{cuda_version}.html\n",
        "!pip install torch-sparse -f https://data.pyg.org/whl/torch-{torch_version}+cu{cuda_version}.html\n",
        "\n",
        "import scipy.sparse\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.neighbors import kneighbors_graph\n",
        "from tqdm import tqdm\n",
        "from torch_geometric.data import Data\n",
        "from torch_geometric.loader import NeighborSampler\n",
        "import os\n",
        "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
        "\n",
        "# Mount Google Drive (if using Google Colab)\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Device Configuration\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f'Using device: {device}')\n",
        "\n",
        "# Load the split data files (train, validation, test)\n",
        "print(\"Loading datasets...\")\n",
        "train_file = '/content/drive/MyDrive/modbus/train_data.csv'\n",
        "val_file = '/content/drive/MyDrive/modbus/val_data.csv'\n",
        "test_file = '/content/drive/MyDrive/modbus/test_data.csv'\n",
        "\n",
        "# Read each file\n",
        "train_data = pd.read_csv(train_file, low_memory=False)\n",
        "val_data = pd.read_csv(val_file, low_memory=False)\n",
        "test_data = pd.read_csv(test_file, low_memory=False)\n",
        "\n",
        "# Normalize each dataset independently\n",
        "scaler = StandardScaler()\n",
        "train_scaled = scaler.fit_transform(train_data)\n",
        "val_scaled = scaler.transform(val_data)\n",
        "test_scaled = scaler.transform(test_data)\n",
        "\n",
        "# Convert scaled data into numpy arrays for processing\n",
        "train_scaled = np.array(train_scaled, dtype=np.float32)\n",
        "val_scaled = np.array(val_scaled, dtype=np.float32)\n",
        "test_scaled = np.array(test_scaled, dtype=np.float32)\n",
        "\n",
        "# Function to create a KNN graph using Scikit-learn's kneighbors_graph function\n",
        "def create_knn_graph(data, k, batch_size=1000):\n",
        "    \"\"\"Creates a KNN graph using the kneighbors_graph function with batched data.\"\"\"\n",
        "    n_samples = data.shape[0]\n",
        "    n_batches = (n_samples - 1) // batch_size + 1\n",
        "\n",
        "    knn_graphs = []\n",
        "\n",
        "    for i in tqdm(range(0, n_samples, batch_size), total=n_batches, desc=\"Creating KNN graph\"):\n",
        "        batch = data[i:i+batch_size]\n",
        "        batch_knn = kneighbors_graph(batch, n_neighbors=k, mode='connectivity', include_self=False, n_jobs=-1)\n",
        "        knn_graphs.append(batch_knn)\n",
        "\n",
        "    return scipy.sparse.vstack(knn_graphs)\n",
        "\n",
        "# Create KNN graphs for each dataset\n",
        "k = 2  # Define k for neighbors\n",
        "\n",
        "print(\"Creating KNN graph for train data...\")\n",
        "train_knn_graph = create_knn_graph(train_scaled, k)\n",
        "\n",
        "print(\"Creating KNN graph for validation data...\")\n",
        "val_knn_graph = create_knn_graph(val_scaled, k)\n",
        "\n",
        "print(\"Creating KNN graph for test data...\")\n",
        "test_knn_graph = create_knn_graph(test_scaled, k)\n",
        "\n",
        "# Convert CSR format to edge_index format for PyTorch Geometric\n",
        "def knn_to_edge_index(knn_graph):\n",
        "    \"\"\"Converts a KNN graph from CSR format to COO and then to edge_index for PyTorch Geometric.\"\"\"\n",
        "    knn_coo = knn_graph.tocoo()\n",
        "\n",
        "    edge_index_np = np.array([knn_coo.row, knn_coo.col])\n",
        "    edge_index = torch.from_numpy(edge_index_np).long()\n",
        "\n",
        "    return edge_index\n",
        "\n",
        "train_edge_index = knn_to_edge_index(train_knn_graph)\n",
        "val_edge_index = knn_to_edge_index(val_knn_graph)\n",
        "test_edge_index = knn_to_edge_index(test_knn_graph)\n",
        "\n",
        "# Convert the scaled datasets to PyTorch tensors\n",
        "train_features = torch.tensor(train_scaled, dtype=torch.float32).to(device)\n",
        "val_features = torch.tensor(val_scaled, dtype=torch.float32).to(device)\n",
        "test_features = torch.tensor(test_scaled, dtype=torch.float32).to(device)\n",
        "\n",
        "# Create PyTorch Geometric Data objects for each dataset\n",
        "train_data = Data(x=train_features, edge_index=train_edge_index)\n",
        "val_data = Data(x=val_features, edge_index=val_edge_index)\n",
        "test_data = Data(x=test_features, edge_index=test_edge_index)\n",
        "\n",
        "# UHG GraphSAGE Layer Definition\n",
        "class UHGGraphSAGELayer(nn.Module):\n",
        "    def __init__(self, in_features, out_features):\n",
        "        super(UHGGraphSAGELayer, self).__init__()\n",
        "        self.weight_neigh = nn.Parameter(torch.Tensor(out_features, in_features))\n",
        "        self.weight_self = nn.Parameter(torch.Tensor(out_features, in_features))\n",
        "        self.reset_parameters()\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        nn.init.kaiming_uniform_(self.weight_neigh, a=np.sqrt(5))\n",
        "        nn.init.kaiming_uniform_(self.weight_self, a=np.sqrt(5))\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        row, col = edge_index\n",
        "\n",
        "        # Neighbor aggregation\n",
        "        neigh_sum = torch.zeros_like(x)\n",
        "        neigh_sum.index_add_(0, row, x[col])\n",
        "        neigh_count = torch.zeros(x.size(0), device=x.device)\n",
        "        neigh_count.index_add_(0, row, torch.ones_like(row, dtype=torch.float))\n",
        "        neigh_count = torch.clamp(neigh_count.unsqueeze(1), min=1)\n",
        "        neigh_features = neigh_sum / neigh_count\n",
        "\n",
        "        # Apply linear transformations\n",
        "        neigh_transformed = torch.matmul(neigh_features, self.weight_neigh.t())\n",
        "        self_transformed = torch.matmul(x, self.weight_self.t())\n",
        "\n",
        "        # Combine using UHG-inspired operation (simplified addition)\n",
        "        combined = neigh_transformed + self_transformed\n",
        "\n",
        "        return F.leaky_relu(combined, negative_slope=0.01)\n",
        "\n",
        "# UHG GraphSAGE Model Definition\n",
        "class UHGGraphSAGE(nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels, out_channels, num_layers, dropout=0.4):\n",
        "        super(UHGGraphSAGE, self).__init__()\n",
        "        self.layers = nn.ModuleList()\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "\n",
        "        self.layers.append(UHGGraphSAGELayer(in_channels, hidden_channels))\n",
        "        for _ in range(num_layers - 2):\n",
        "            self.layers.append(UHGGraphSAGELayer(hidden_channels, hidden_channels))\n",
        "        self.layers.append(UHGGraphSAGELayer(hidden_channels, out_channels))\n",
        "\n",
        "    def forward(self, x, adjs=None, edge_index=None):\n",
        "      if adjs is not None:  # Training with neighborhood sampling\n",
        "        for i, (edge_index, _, size) in enumerate(adjs):\n",
        "            x_target = x[:size[1]]  # Target nodes for the current layer\n",
        "            x = self.layers[i](x, edge_index)\n",
        "      else:  # Full graph evaluation (no sampling)\n",
        "        for layer in self.layers:\n",
        "            x = layer(x, edge_index)\n",
        "      return x\n",
        "\n",
        "# Initialize the model\n",
        "in_channels = train_features.size(1)\n",
        "hidden_channels = 32\n",
        "out_channels = in_channels\n",
        "num_layers = 2\n",
        "model = UHGGraphSAGE(in_channels=in_channels, hidden_channels=hidden_channels,\n",
        "                     out_channels=out_channels, num_layers=num_layers).to(device)\n",
        "\n",
        "# Loss and optimizer\n",
        "criterion = nn.MSELoss()  # Use MSE to reconstruct node features\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0001, weight_decay=1e-3)\n",
        "\n",
        "# Learning rate scheduler\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=3, verbose=True)\n",
        "\n",
        "# Neighborhood sampler with 10 neighbors at each layer\n",
        "train_loader = NeighborSampler(train_data.edge_index, sizes=[10, 10], batch_size=64, shuffle=True)\n",
        "\n",
        "# Training with neighborhood sampling\n",
        "def train_with_sampling(model, optimizer, loader, data, criterion, device, accumulation_steps=8):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # Add an explicit loop counter\n",
        "    for batch_idx, (batch_size, n_id, adjs) in enumerate(tqdm(loader, desc=\"Training\")):\n",
        "        adjs = [adj.to(device) for adj in adjs]\n",
        "        batch_x = data.x[n_id].to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        out = model(batch_x, adjs)\n",
        "\n",
        "        # Compute loss for the target nodes only (first batch_size nodes in the batch)\n",
        "        loss = criterion(out[:batch_size], batch_x[:batch_size]) / accumulation_steps\n",
        "        loss.backward()\n",
        "\n",
        "        # Accumulate gradients and update model weights every accumulation_steps\n",
        "        if (batch_idx + 1) % accumulation_steps == 0:\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "            optimizer.step()  # Update weights\n",
        "            optimizer.zero_grad()  # Reset gradients for the next accumulation\n",
        "            total_loss += loss.item() * accumulation_steps  # Accumulate loss\n",
        "\n",
        "    return total_loss / len(loader.dataset)\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def evaluate(model, data, criterion, device):\n",
        "    model.eval()\n",
        "    x = data.x.to(device)\n",
        "    edge_index = data.edge_index.to(device)\n",
        "\n",
        "    # Perform forward pass without sampling\n",
        "    out = model(x, edge_index=edge_index)\n",
        "\n",
        "    # Loss computation\n",
        "    loss = criterion(out, x)\n",
        "    return loss.item()\n",
        "\n",
        "num_epochs = 400\n",
        "for epoch in range(1, num_epochs + 1):\n",
        "    # Training with sampling\n",
        "    train_loss = train_with_sampling(model, optimizer, train_loader, train_data, criterion, device)\n",
        "\n",
        "    # Evaluate on validation set\n",
        "    val_loss = evaluate(model, val_data, criterion, device)\n",
        "\n",
        "    print(f'Epoch {epoch}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "8XrTq8Zxeoc2",
        "outputId": "84627d2c-ac71-4f8e-8e3b-e24d11ba81fa"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: faiss-gpu in /usr/local/lib/python3.10/dist-packages (1.7.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.4.0+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.6.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Requirement already satisfied: torch_geometric in /usr/local/lib/python3.10/dist-packages (2.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.10.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (2024.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.1.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.26.4)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.1.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (4.66.5)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (2.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (1.11.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (4.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch_geometric) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2024.8.30)\n",
            "Requirement already satisfied: typing-extensions>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from multidict<7.0,>=4.5->aiohttp->torch_geometric) (4.12.2)\n",
            "Requirement already satisfied: faiss-cpu in /usr/local/lib/python3.10/dist-packages (1.8.0.post1)\n",
            "Requirement already satisfied: numpy<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from faiss-cpu) (1.26.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from faiss-cpu) (24.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.5)\n",
            "Requirement already satisfied: scapy in /usr/local/lib/python3.10/dist-packages (2.5.0)\n",
            "Requirement already satisfied: geoopt in /usr/local/lib/python3.10/dist-packages (0.5.0)\n",
            "Requirement already satisfied: torch>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from geoopt) (2.4.0+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from geoopt) (1.26.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from geoopt) (1.13.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->geoopt) (3.16.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->geoopt) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->geoopt) (1.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->geoopt) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->geoopt) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->geoopt) (2024.6.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.9.0->geoopt) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.9.0->geoopt) (1.3.0)\n",
            "Looking in links: https://data.pyg.org/whl/torch-2.4.0+cu121.html\n",
            "Requirement already satisfied: torch-scatter in /usr/local/lib/python3.10/dist-packages (2.1.2+pt24cu121)\n",
            "Looking in links: https://data.pyg.org/whl/torch-2.4.0+cu121.html\n",
            "Requirement already satisfied: torch-sparse in /usr/local/lib/python3.10/dist-packages (0.6.18+pt24cu121)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch-sparse) (1.13.1)\n",
            "Requirement already satisfied: numpy<2.3,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from scipy->torch-sparse) (1.26.4)\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Using device: cpu\n",
            "Loading datasets...\n",
            "Creating KNN graph for train data...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Creating KNN graph: 100%|██████████| 700/700 [00:13<00:00, 52.12it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating KNN graph for validation data...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Creating KNN graph: 100%|██████████| 150/150 [00:03<00:00, 43.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating KNN graph for test data...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Creating KNN graph: 100%|██████████| 150/150 [00:04<00:00, 37.39it/s]\n",
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
            "  warnings.warn(\n",
            "Training: 100%|██████████| 10938/10938 [00:19<00:00, 557.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Train Loss: 0.0012, Val Loss: 0.4391\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 10938/10938 [00:19<00:00, 570.15it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2, Train Loss: 0.0006, Val Loss: 0.3580\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 10938/10938 [00:19<00:00, 549.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3, Train Loss: 0.0006, Val Loss: 0.3568\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 10938/10938 [00:18<00:00, 579.25it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4, Train Loss: 0.0006, Val Loss: 0.3548\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 10938/10938 [00:18<00:00, 582.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5, Train Loss: 0.0006, Val Loss: 0.3480\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 10938/10938 [00:18<00:00, 596.30it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6, Train Loss: 0.0006, Val Loss: 0.3415\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 10938/10938 [00:19<00:00, 574.40it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7, Train Loss: 0.0005, Val Loss: 0.3365\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 10938/10938 [00:18<00:00, 587.91it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8, Train Loss: 0.0005, Val Loss: 0.3383\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 10938/10938 [00:18<00:00, 582.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9, Train Loss: 0.0005, Val Loss: 0.3373\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 10938/10938 [00:18<00:00, 589.64it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10, Train Loss: 0.0004, Val Loss: 0.3390\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 10938/10938 [00:18<00:00, 587.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11, Train Loss: 0.0004, Val Loss: 0.3480\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 10938/10938 [00:18<00:00, 594.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12, Train Loss: 0.0004, Val Loss: 0.3524\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 10938/10938 [00:18<00:00, 587.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13, Train Loss: 0.0003, Val Loss: 0.3638\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 10938/10938 [00:18<00:00, 594.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14, Train Loss: 0.0003, Val Loss: 0.3691\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 10938/10938 [00:18<00:00, 589.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15, Train Loss: 0.0002, Val Loss: 0.3919\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 10938/10938 [00:18<00:00, 586.56it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 16, Train Loss: 0.0002, Val Loss: 0.4122\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 10938/10938 [00:19<00:00, 573.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 17, Train Loss: 0.0002, Val Loss: 0.4340\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 10938/10938 [00:18<00:00, 586.50it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 18, Train Loss: 0.0001, Val Loss: 0.4598\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 10938/10938 [00:19<00:00, 565.70it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 19, Train Loss: 0.0001, Val Loss: 0.4842\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 10938/10938 [00:19<00:00, 575.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 20, Train Loss: 0.0001, Val Loss: 0.5092\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 10938/10938 [00:18<00:00, 603.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 21, Train Loss: 0.0001, Val Loss: 0.5331\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 10938/10938 [00:18<00:00, 586.30it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 22, Train Loss: 0.0001, Val Loss: 0.5343\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 10938/10938 [00:18<00:00, 594.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 23, Train Loss: 0.0000, Val Loss: 0.5326\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 10938/10938 [00:18<00:00, 595.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 24, Train Loss: 0.0000, Val Loss: 0.5203\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 10938/10938 [00:18<00:00, 604.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 25, Train Loss: 0.0000, Val Loss: 0.5069\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 10938/10938 [00:18<00:00, 596.89it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 26, Train Loss: 0.0000, Val Loss: 0.4992\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 10938/10938 [00:18<00:00, 599.90it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 27, Train Loss: 0.0000, Val Loss: 0.4985\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 10938/10938 [00:18<00:00, 594.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 28, Train Loss: 0.0000, Val Loss: 0.4945\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 10938/10938 [00:18<00:00, 594.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 29, Train Loss: 0.0000, Val Loss: 0.4870\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 10938/10938 [00:18<00:00, 595.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 30, Train Loss: 0.0000, Val Loss: 0.4838\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 10938/10938 [00:18<00:00, 599.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 31, Train Loss: 0.0000, Val Loss: 0.4798\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 10938/10938 [00:18<00:00, 592.18it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 32, Train Loss: 0.0000, Val Loss: 0.4757\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 10938/10938 [00:18<00:00, 589.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 33, Train Loss: 0.0000, Val Loss: 0.4696\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 10938/10938 [00:18<00:00, 597.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 34, Train Loss: 0.0000, Val Loss: 0.4613\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 10938/10938 [00:18<00:00, 592.71it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 35, Train Loss: 0.0000, Val Loss: 0.4537\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 10938/10938 [00:18<00:00, 591.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 36, Train Loss: 0.0000, Val Loss: 0.4197\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 10938/10938 [00:18<00:00, 593.68it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 37, Train Loss: 0.0000, Val Loss: 0.4120\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 10938/10938 [00:18<00:00, 604.38it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 38, Train Loss: 0.0000, Val Loss: 0.3939\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 10938/10938 [00:18<00:00, 600.70it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 39, Train Loss: 0.0000, Val Loss: 0.3888\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 10938/10938 [00:18<00:00, 601.33it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 40, Train Loss: 0.0000, Val Loss: 0.3816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 10938/10938 [00:18<00:00, 588.11it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 41, Train Loss: 0.0000, Val Loss: 0.3788\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 10938/10938 [00:18<00:00, 591.00it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 42, Train Loss: 0.0000, Val Loss: 0.3738\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 10938/10938 [00:18<00:00, 604.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 43, Train Loss: 0.0000, Val Loss: 0.3698\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 10938/10938 [00:18<00:00, 595.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 44, Train Loss: 0.0000, Val Loss: 0.3662\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 10938/10938 [00:18<00:00, 596.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 45, Train Loss: 0.0000, Val Loss: 0.3639\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 10938/10938 [00:18<00:00, 602.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 46, Train Loss: 0.0000, Val Loss: 0.3543\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 10938/10938 [00:18<00:00, 602.96it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 47, Train Loss: 0.0000, Val Loss: 0.3517\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 10938/10938 [00:18<00:00, 603.13it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 48, Train Loss: 0.0000, Val Loss: 0.3500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 10938/10938 [00:18<00:00, 601.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 49, Train Loss: 0.0000, Val Loss: 0.3464\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 10938/10938 [00:18<00:00, 588.18it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 50, Train Loss: 0.0000, Val Loss: 0.3452\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 10938/10938 [00:18<00:00, 598.17it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 51, Train Loss: 0.0000, Val Loss: 0.3524\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 10938/10938 [00:18<00:00, 606.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 52, Train Loss: 0.0000, Val Loss: 0.3510\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 10938/10938 [00:19<00:00, 564.92it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 53, Train Loss: 0.0000, Val Loss: 0.3501\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 10938/10938 [00:19<00:00, 561.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 54, Train Loss: 0.0000, Val Loss: 0.3400\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 10938/10938 [00:18<00:00, 599.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 55, Train Loss: 0.0000, Val Loss: 0.3276\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 10938/10938 [00:17<00:00, 609.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 56, Train Loss: 0.0000, Val Loss: 0.3349\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 10938/10938 [00:18<00:00, 597.44it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 57, Train Loss: 0.0000, Val Loss: 0.3332\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 10938/10938 [00:20<00:00, 544.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 58, Train Loss: 0.0000, Val Loss: 0.3316\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 10938/10938 [00:19<00:00, 566.12it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 59, Train Loss: 0.0000, Val Loss: 0.3258\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 10938/10938 [00:19<00:00, 560.33it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 60, Train Loss: 0.0000, Val Loss: 0.3196\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 10938/10938 [00:19<00:00, 571.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 61, Train Loss: 0.0000, Val Loss: 0.3213\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 10938/10938 [00:18<00:00, 599.12it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 62, Train Loss: 0.0000, Val Loss: 0.3194\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 10938/10938 [00:18<00:00, 590.95it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 63, Train Loss: 0.0000, Val Loss: 0.3132\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 10938/10938 [00:18<00:00, 586.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 64, Train Loss: 0.0000, Val Loss: 0.3126\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 10938/10938 [00:18<00:00, 604.99it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 65, Train Loss: 0.0000, Val Loss: 0.3055\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 10938/10938 [00:17<00:00, 609.71it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 66, Train Loss: 0.0000, Val Loss: 0.2932\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 10938/10938 [00:18<00:00, 605.14it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 67, Train Loss: 0.0000, Val Loss: 0.2973\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 10938/10938 [00:18<00:00, 603.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 68, Train Loss: 0.0000, Val Loss: 0.2841\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 10938/10938 [00:18<00:00, 596.07it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 69, Train Loss: 0.0000, Val Loss: 0.2826\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:  62%|██████▏   | 6751/10938 [00:11<00:07, 581.12it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-7a8086b32e49>\u001b[0m in \u001b[0;36m<cell line: 225>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    225\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m     \u001b[0;31m# Training with sampling\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 227\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_with_sampling\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    228\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[0;31m# Evaluate on validation set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-22-7a8086b32e49>\u001b[0m in \u001b[0;36mtrain_with_sampling\u001b[0;34m(model, optimizer, loader, data, criterion, device, accumulation_steps)\u001b[0m\n\u001b[1;32m    202\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbatch_idx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0maccumulation_steps\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Update weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Reset gradients for the next accumulation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m             \u001b[0mtotal_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0maccumulation_steps\u001b[0m  \u001b[0;31m# Accumulate loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    482\u001b[0m                             )\n\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 484\u001b[0;31m                 \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    485\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optimizer_step_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36m_use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0mprev_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_grad_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0;31m# Note on graph break below:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rr2db7-AjBl-"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}